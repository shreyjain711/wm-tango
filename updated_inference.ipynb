{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3930b9f2-881a-4d82-8153-0e009b50ef31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'wm-tango' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/shreyjain711/wm-tango.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738ababf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/wm-tango\n",
      "/home/ec2-user/SageMaker/wm-tango\r\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/ec2-user/SageMaker/wm-tango'\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e09d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c21ccbd-eec9-4044-a13c-2f1fcc738746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools==70.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (70.3.0)\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jax 0.4.23 requires scipy>=1.9, but you have scipy 1.8.0 which is incompatible.\n",
      "jaxlib 0.4.23 requires scipy>=1.9, but you have scipy 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install setuptools==70.3.0\n",
    "!pip install -r requirements.txt --quiet\n",
    "!pip install jax==0.4.23 --quiet\n",
    "!pip install jaxlib==0.4.23 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402efbd1-e6e6-44a8-9c7f-4f5913d8b92e",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00826120376586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Fetching 9 files",
       "rate": null,
       "total": 9,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378565e294424c939ba800ccceb87259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005129814147949219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading pytorch_model_main.bin",
       "rate": null,
       "total": 4829066767,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400528f343c347788becf9cfe4da520a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model_main.bin:   0%|          | 0.00/4.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/wm-tango/audioldm/audio/stft.py:42: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = pad_center(fft_window, filter_length)\n",
      "/home/ec2-user/SageMaker/wm-tango/audioldm/audio/stft.py:151: FutureWarning: Pass sr=16000, n_fft=1024, n_mels=64, fmin=0, fmax=8000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa_mel_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet initialized randomly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/flan-t5-large were not used when initializing T5EncoderModel: ['decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'lm_head.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.19.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.17.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.22.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.21.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.final_layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.15.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.18.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.embed_tokens.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.15.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded checkpoint from: declare-lab/tango2\n",
      "DBG torch.Size([1, 8, 256, 16])\n"
     ]
    }
   ],
   "source": [
    "# # Environmental Sounds\n",
    "\n",
    "\n",
    "\n",
    "import IPython\n",
    "import soundfile as sf\n",
    "from tango import Tango\n",
    "\n",
    "tango = Tango(\"declare-lab/tango2\")\n",
    "\n",
    "\n",
    "prompt = 'Birds chirping in a dense forest at sunrise'\n",
    "audio1, init_latents = tango.generate(prompt, wm_flag=True)\n",
    "sf.write(f\"wm_p{p_num}.wav\", audio1, samplerate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d227cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.9536, -0.1465, -0.1014,  ..., -0.0411,  0.0919,  0.0821],\n",
       "          [-0.0496, -0.1481, -0.1028,  ..., -0.0430,  0.0877,  0.0775],\n",
       "          [-0.0527, -0.1491, -0.1033,  ..., -0.0448,  0.0832,  0.0724],\n",
       "          ...,\n",
       "          [-0.0373, -0.1381, -0.0920,  ..., -0.0344,  0.1018,  0.0930],\n",
       "          [-0.0403, -0.1415, -0.0960,  ..., -0.0368,  0.0989,  0.0899],\n",
       "          [-0.0433, -0.1443, -0.0991,  ..., -0.0390,  0.0956,  0.0863]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13db2d5d-0e5a-4b4e-bab3-397065eab027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming necessary imports and initializations\n",
    "# batch_size = 1\n",
    "# audio_shape = (1, 1, 16000)  # Adjust based on TANGO's expected input shape\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Original noise\n",
    "# noise = torch.randn(batch_size, *audio_shape, device=device)\n",
    "\n",
    "# # Perform FFT\n",
    "# F_noise = torch.fft.fft(noise)\n",
    "\n",
    "# # Create a mask for the watermark (define create_watermark_mask accordingly)\n",
    "# def create_watermark_mask(shape):\n",
    "#     mask = torch.zeros(shape, dtype=torch.bool)\n",
    "#     # Example: Set mask for specific frequency bands\n",
    "#     mask[..., 100:200] = True\n",
    "#     return mask\n",
    "\n",
    "# mask = create_watermark_mask(F_noise.shape)\n",
    "\n",
    "# # Define the watermark pattern\n",
    "# watermark_pattern = torch.rand(mask.sum(), device=device)\n",
    "\n",
    "# # Embed the watermark\n",
    "# F_noise[mask] = watermark_pattern\n",
    "\n",
    "# # Inverse FFT to get the watermarked noise\n",
    "# watermarked_noise = torch.fft.ifft(F_noise).real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d650b7df-9d41-4774-b80f-87fbab05a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In TANGO's generation code\n",
    "# Original noise initialization\n",
    "# noise = torch.randn(batch_size, *audio_shape, device=device)\n",
    "\n",
    "# Use watermarked noise instead\n",
    "# noise = watermarked_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48f7b41-b026-45b9-a512-eb7cb86d57be",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007164716720581055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Fetching 9 files",
       "rate": null,
       "total": 9,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f200d502d6c6476599a70469ba9553cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/wm-tango/audioldm/audio/stft.py:42: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = pad_center(fft_window, filter_length)\n",
      "/home/ec2-user/SageMaker/wm-tango/audioldm/audio/stft.py:151: FutureWarning: Pass sr=16000, n_fft=1024, n_mels=64, fmin=0, fmax=8000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa_mel_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet initialized randomly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/flan-t5-large were not used when initializing T5EncoderModel: ['decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.13.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.15.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.final_layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.21.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.embed_tokens.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'lm_head.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.16.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.23.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded checkpoint from: declare-lab/tango\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# from huggingface_hub import snapshot_download\n",
    "# from models import AudioDiffusion, DDPMScheduler\n",
    "# from audioldm.audio.stft import TacotronSTFT\n",
    "# from audioldm.variational_autoencoder import AutoencoderKL\n",
    "\n",
    "\n",
    "# class AudioDiffusionInversion:\n",
    "#     def __init__(self, name=\"declare-lab/tango\", device=\"cuda:0\"):\n",
    "        \n",
    "#         self.device = device\n",
    "        \n",
    "#         path = snapshot_download(repo_id=name)\n",
    "        \n",
    "#         vae_config = json.load(open(\"{}/vae_config.json\".format(path)))\n",
    "#         stft_config = json.load(open(\"{}/stft_config.json\".format(path)))\n",
    "#         main_config = json.load(open(\"{}/main_config.json\".format(path)))\n",
    "        \n",
    "#         self.vae = AutoencoderKL(**vae_config).to(device)\n",
    "#         self.stft = TacotronSTFT(**stft_config).to(device)\n",
    "#         self.model = AudioDiffusion(**main_config).to(device)\n",
    "        \n",
    "#         vae_weights = torch.load(\"{}/pytorch_model_vae.bin\".format(path), map_location=device)\n",
    "#         stft_weights = torch.load(\"{}/pytorch_model_stft.bin\".format(path), map_location=device)\n",
    "#         main_weights = torch.load(\"{}/pytorch_model_main.bin\".format(path), map_location=device)\n",
    "        \n",
    "#         self.vae.load_state_dict(vae_weights)\n",
    "#         self.stft.load_state_dict(stft_weights)\n",
    "#         self.model.load_state_dict(main_weights)\n",
    "\n",
    "#         print (\"Successfully loaded checkpoint from:\", name)\n",
    "        \n",
    "#         self.vae.eval()\n",
    "#         self.stft.eval()\n",
    "#         self.model.eval()\n",
    "        \n",
    "#         self.scheduler = DDPMScheduler.from_pretrained(main_config[\"scheduler_name\"], subfolder=\"scheduler\")\n",
    "        \n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def get_latents_from_audio(self, audio_waveform):\n",
    "#         \"\"\"\n",
    "#         Encodes audio into latents using STFT and VAE.\n",
    "#         :param audio_waveform: Input waveform to encode.\n",
    "#         :return: Latent representation of the audio.\n",
    "#         \"\"\"\n",
    "#         mel_spectrogram, _, _ = self.stft.mel_spectrogram(audio_waveform.unsqueeze(0).to(self.device))\n",
    "#         latents = self.vae.encode_first_stage(mel_spectrogram.unsqueeze(0)).sample()\n",
    "#         return latents\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def backward_diffusion(self, latents, num_inference_steps=50, encoder_hidden_states=None):\n",
    "#         self.scheduler.set_timesteps(num_inference_steps, device=latents.device)\n",
    "#         timesteps = self.scheduler.timesteps\n",
    "\n",
    "#         for t in tqdm(reversed(timesteps), desc=\"Reversing Diffusion\"):\n",
    "#             alpha_prod_t = self.scheduler.alphas_cumprod[t]\n",
    "#             beta_prod_t = 1 - alpha_prod_t\n",
    "\n",
    "#             print(f\"Timestep {t}: alpha_prod_t={alpha_prod_t}, beta_prod_t={beta_prod_t}\")\n",
    "\n",
    "#             noise_pred = self.model.unet(latents, t, encoder_hidden_states=encoder_hidden_states).sample\n",
    "\n",
    "#             print(f\"Timestep {t}: noise_pred min={noise_pred.min()}, max={noise_pred.max()}\")\n",
    "#             latents = (\n",
    "#                 (latents - beta_prod_t.sqrt() * noise_pred)  # Remove predicted noise\n",
    "#                 / (alpha_prod_t.sqrt() + 1e-7)  # Add small epsilon for stability\n",
    "#             )\n",
    "\n",
    "#             print(f\"Timestep {t}: latents min={latents.min()}, max={latents.max()}\")\n",
    "#         return latents\n",
    "\n",
    "# #     def backward_diffusion(self, latents, num_inference_steps=50, encoder_hidden_states = None):\n",
    "# #         \"\"\"\n",
    "# #         Performs the backward diffusion process to reconstruct noise.\n",
    "\n",
    "# #         :param latents: Initial latent variables (e.g., generated from a VAE or forward diffusion process).\n",
    "# #         :param num_inference_steps: Number of diffusion steps to reverse the process.\n",
    "# #         :return: Reconstructed latents representing the noise.\n",
    "# #         \"\"\"\n",
    "# #         # Set up the scheduler for backward diffusion\n",
    "# #         self.scheduler.set_timesteps(num_inference_steps, device=latents.device)  # Use self.scheduler here\n",
    "# #         timesteps = self.scheduler.timesteps\n",
    "\n",
    "# #         # Start the reverse diffusion process\n",
    "# #         for t in tqdm(reversed(timesteps), desc=\"Reversing Diffusion\"):\n",
    "# #             # Current alpha value\n",
    "# #             alpha_prod_t = self.scheduler.alphas_cumprod[t]\n",
    "# #             beta_prod_t = 1 - alpha_prod_t\n",
    "\n",
    "# #             # Predict the noise added at this step\n",
    "# #             print(f\"UNET CONFIGURATION {self.model.unet.config}\")\n",
    "# #             print(f\"[DEBUG] UNet Input Channels: {self.model.unet.config.in_channels}\")\n",
    "\n",
    "# #             noise_pred = self.model.unet(\n",
    "# #     latents, t, encoder_hidden_states=encoder_hidden_states\n",
    "# # ).sample\n",
    "\n",
    "\n",
    "\n",
    "# #             # Update the latents to the previous step\n",
    "# #             latents = (\n",
    "# #                 (latents - beta_prod_t.sqrt() * noise_pred)  # Remove predicted noise\n",
    "# #                 / alpha_prod_t.sqrt()  # Scale by alpha\n",
    "# #             )\n",
    "\n",
    "# #         return latents\n",
    "    \n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def reconstruct_audio(self, latents):\n",
    "#         \"\"\"\n",
    "#         Reconstructs audio waveform from latents.\n",
    "#         :param latents: Latent variables.\n",
    "#         :return: Reconstructed audio waveform.\n",
    "#         \"\"\"\n",
    "#         mel_spectrogram = self.vae.decode_first_stage(latents)\n",
    "#         audio_waveform = self.vae.decode_to_waveform(mel_spectrogram)\n",
    "#         return audio_waveform\n",
    "\n",
    "# #     def invert(self, audio_waveform, num_inference_steps=50):\n",
    "# #         \"\"\"\n",
    "# #         Inverts an audio waveform through the diffusion pipeline.\n",
    "# #         :param audio_waveform: Input waveform to invert.\n",
    "# #         :param stft: STFT processor.\n",
    "# #         :param num_inference_steps: Number of diffusion steps.\n",
    "# #         :return: Reconstructed waveform and initial noise.\n",
    "# #         \"\"\"\n",
    "# #         latents = self.get_latents_from_audio(audio_waveform)#.transpose(-3, -2)\n",
    "# #         print(\"Latents shape: \", latents.shape)\n",
    "# #         noise_latents = self.backward_diffusion(latents, num_inference_steps=num_inference_steps)\n",
    "# # #         reconstructed_waveform = self.reconstruct_audio(latents)\n",
    "# #         return noise_latents\n",
    "\n",
    "#     def invert(self, audio_waveform, prompt=None, num_inference_steps=50):\n",
    "#         \"\"\"\n",
    "#         Inverts an audio waveform through the diffusion pipeline.\n",
    "#         :param audio_waveform: Input waveform to invert.\n",
    "#         :param prompt: Optional text prompt for conditional inversion.\n",
    "#         :param num_inference_steps: Number of diffusion steps.\n",
    "#         :return: Reconstructed waveform and initial noise.\n",
    "#         \"\"\"\n",
    "#         # Get latents from the input audio\n",
    "#         latents = self.get_latents_from_audio(audio_waveform)\n",
    "# #         print(\"DBG\", latents.shape)\n",
    "\n",
    "#         # Encode text if prompt is provided, else set to zero (unconditional)\n",
    "#         if prompt:\n",
    "#             encoder_hidden_states, boolean_encoder_mask = self.model.encode_text(prompt)\n",
    "#         else:\n",
    "#             # Unconditional mode: Set encoder_hidden_states to zeros\n",
    "#             encoder_hidden_states = torch.zeros(\n",
    "#                 (1, 1, self.model.unet.config.cross_attention_dim),\n",
    "#                 device=latents.device\n",
    "#             )\n",
    "#             boolean_encoder_mask = None\n",
    "\n",
    "#         # Perform the reverse diffusion process\n",
    "#         noise_latents = self.backward_diffusion(\n",
    "#             latents,\n",
    "#             num_inference_steps=num_inference_steps,\n",
    "#             encoder_hidden_states=encoder_hidden_states\n",
    "#         )\n",
    "\n",
    "#         return noise_latents\n",
    "\n",
    "\n",
    "# # Example Usage:\n",
    "# # Initialize your model, scheduler, and STFT processor.\n",
    "# # Initialize your model, scheduler, and STFT processor.\n",
    "# # tango = Tango(name=\"declare-lab/tango\")\n",
    "\n",
    "# import numpy as np\n",
    "# import librosa\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "# def load_audio(file_path):\n",
    "#     \"\"\"Load audio file using librosa.\"\"\"\n",
    "#     audio, sr = librosa.load(file_path, sr=None)  # Load audio with native sampling rate\n",
    "#     return audio, sr\n",
    "\n",
    "# inversion_pipeline = AudioDiffusionInversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8649b75b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0068912506103515625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Fetching 9 files",
       "rate": null,
       "total": 9,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cf1a7fd59e4ef58bbe949713015460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/wm-tango/audioldm/audio/stft.py:42: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = pad_center(fft_window, filter_length)\n",
      "/home/ec2-user/SageMaker/wm-tango/audioldm/audio/stft.py:151: FutureWarning: Pass sr=16000, n_fft=1024, n_mels=64, fmin=0, fmax=8000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_basis = librosa_mel_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet initialized randomly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/flan-t5-large were not used when initializing T5EncoderModel: ['decoder.block.11.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.12.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'lm_head.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.9.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.2.DenseReluDense.wi_1.weight', 'decoder.embed_tokens.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.21.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.15.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded checkpoint from: declare-lab/tango\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import snapshot_download\n",
    "from models import AudioDiffusion, DDPMScheduler\n",
    "from audioldm.audio.stft import TacotronSTFT\n",
    "from audioldm.variational_autoencoder import AutoencoderKL\n",
    "\n",
    "\n",
    "class AudioDiffusionInversion:\n",
    "    def __init__(self, name=\"declare-lab/tango\", device=\"cuda:0\"):\n",
    "        self.device = device\n",
    "\n",
    "        # Load model configurations and weights\n",
    "        path = snapshot_download(repo_id=name)\n",
    "        vae_config = json.load(open(f\"{path}/vae_config.json\"))\n",
    "        stft_config = json.load(open(f\"{path}/stft_config.json\"))\n",
    "        main_config = json.load(open(f\"{path}/main_config.json\"))\n",
    "\n",
    "        self.vae = AutoencoderKL(**vae_config).to(device)\n",
    "        self.stft = TacotronSTFT(**stft_config).to(device)\n",
    "        self.model = AudioDiffusion(**main_config).to(device)\n",
    "\n",
    "        self.vae.load_state_dict(torch.load(f\"{path}/pytorch_model_vae.bin\", map_location=device))\n",
    "        self.stft.load_state_dict(torch.load(f\"{path}/pytorch_model_stft.bin\", map_location=device))\n",
    "        self.model.load_state_dict(torch.load(f\"{path}/pytorch_model_main.bin\", map_location=device))\n",
    "\n",
    "        print(f\"Successfully loaded checkpoint from: {name}\")\n",
    "\n",
    "        self.vae.eval()\n",
    "        self.stft.eval()\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scheduler = DDPMScheduler.from_pretrained(main_config[\"scheduler_name\"], subfolder=\"scheduler\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_latents_from_audio(self, audio_waveform):\n",
    "        \"\"\"\n",
    "        Encodes audio into latents using STFT and VAE.\n",
    "        \"\"\"\n",
    "        mel_spectrogram, _, _ = self.stft.mel_spectrogram(audio_waveform.unsqueeze(0).to(self.device))\n",
    "        latents = self.vae.encode_first_stage(mel_spectrogram.unsqueeze(0)).sample()\n",
    "        return latents\n",
    "\n",
    "    @staticmethod\n",
    "    def backward_ddim(x_t, alpha_t, alpha_tm1, eps_xt):\n",
    "        \"\"\"\n",
    "        Reconstructs x_{t-1} from x_t using DDIM-style inversion.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            alpha_tm1**0.5\n",
    "            * (\n",
    "                (alpha_t**-0.5 - alpha_tm1**-0.5) * x_t\n",
    "                + ((1 / alpha_tm1 - 1) ** 0.5 - (1 / alpha_t - 1) ** 0.5) * eps_xt\n",
    "            )\n",
    "            + x_t\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def backward_diffusion(self, latents, encoder_hidden_states, num_inference_steps=50, guidance_scale=7.5):\n",
    "        \"\"\"\n",
    "        Perform backward diffusion to invert latents to noise.\n",
    "        \"\"\"\n",
    "        # Initialize scheduler and scale latents with noise sigma\n",
    "        self.scheduler.set_timesteps(num_inference_steps, device=self.device)\n",
    "        latents = latents * self.scheduler.init_noise_sigma\n",
    "\n",
    "        for t in reversed(self.scheduler.timesteps):\n",
    "            # Expand for classifier-free guidance\n",
    "            if guidance_scale > 1.0:\n",
    "                latent_model_input = torch.cat([latents] * 2)\n",
    "            else:\n",
    "                latent_model_input = latents\n",
    "\n",
    "            latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)\n",
    "\n",
    "            # Predict noise residual\n",
    "            noise_pred = self.model.unet(\n",
    "                latent_model_input, t, encoder_hidden_states=encoder_hidden_states\n",
    "            ).sample\n",
    "\n",
    "            # Classifier-free guidance\n",
    "            if guidance_scale > 1.0:\n",
    "                noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "                noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "            # Calculate alpha values for DDIM update\n",
    "            alpha_t = self.scheduler.alphas_cumprod[t]\n",
    "            alpha_tm1 = (\n",
    "                self.scheduler.alphas_cumprod[t - 1]\n",
    "                if t > 0\n",
    "                else self.scheduler.final_alpha_cumprod\n",
    "            )\n",
    "\n",
    "            # Apply backward DDIM step\n",
    "            latents = self.backward_ddim(\n",
    "                x_t=latents,\n",
    "                alpha_t=alpha_t,\n",
    "                alpha_tm1=alpha_tm1,\n",
    "                eps_xt=noise_pred,\n",
    "            )\n",
    "\n",
    "        return latents\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reconstruct_audio(self, latents):\n",
    "        \"\"\"\n",
    "        Reconstructs audio waveform from latents.\n",
    "        \"\"\"\n",
    "        mel_spectrogram = self.vae.decode_first_stage(latents)\n",
    "        audio_waveform = self.vae.decode_to_waveform(mel_spectrogram)\n",
    "        return audio_waveform\n",
    "\n",
    "    def invert(self, audio_waveform, prompt=None, num_inference_steps=50, guidance_scale=7.5):\n",
    "        \"\"\"\n",
    "        Inverts an audio waveform through the diffusion pipeline.\n",
    "        \"\"\"\n",
    "        # Get latents from the input audio\n",
    "        latents = self.get_latents_from_audio(audio_waveform)\n",
    "\n",
    "        # Get text embeddings if prompt is provided\n",
    "        if prompt:\n",
    "            encoder_hidden_states = self.model.encode_text(prompt)\n",
    "        else:\n",
    "            # Unconditional mode\n",
    "            encoder_hidden_states = torch.zeros(\n",
    "                (1, 1, self.model.unet.config.cross_attention_dim), device=self.device\n",
    "            )\n",
    "\n",
    "        # Perform the reverse diffusion process\n",
    "        noise_latents = self.backward_diffusion(\n",
    "            latents,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "        )\n",
    "\n",
    "        return noise_latents\n",
    "\n",
    "\n",
    "def load_audio(file_path):\n",
    "    \"\"\"Load audio file using librosa.\"\"\"\n",
    "    import librosa\n",
    "    audio, sr = librosa.load(file_path, sr=None)  # Load audio with native sampling rate\n",
    "    return audio, sr\n",
    "\n",
    "\n",
    "# Initialize the inversion pipeline\n",
    "inversion_pipeline = AudioDiffusionInversion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39df7970-af94-4834-88a9-cd2a45ba582a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>waveform, sr = load_audio(<span style=\"color: #808000; text-decoration-color: #808000\">'generated_samples/wm_p1_n1_c7.wav'</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>waveform = torch.tensor(waveform)                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>prompt= <span style=\"color: #808000; text-decoration-color: #808000\">'Birds chirping in a dense forest at sunrise'</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>4 noise = inversion_pipeline.invert(waveform, prompt = prompt, num_inference_steps=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">100</span>)        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>reconstructed_waveform = inversion_pipeline.reconstruct_audio(noise)                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">invert</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">131</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Perform the reverse diffusion process</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>131 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>noise_latents = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.backward_diffusion(                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>latents,                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>encoder_hidden_states=encoder_hidden_states,                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>num_inference_steps=num_inference_steps,                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">grad_mode.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.clone():                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 27 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(F, decorate_context)                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrap_generator</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, func):                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward_diffusion</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">78</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>latent_model_input = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scheduler.scale_model_input(latent_model_input, t)   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Predict noise residual</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 78 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>noise_pred = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.unet(                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>latent_model_input, t, encoder_hidden_states=encoder_hidden_states         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 80 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>).sample                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 81 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">94</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unet_2d_cond</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ition.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">905</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">902 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>down_block_res_samples = (sample,)                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">903 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> downsample_block <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.down_blocks:                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">904 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(downsample_block, <span style=\"color: #808000; text-decoration-color: #808000\">\"has_cross_attention\"</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> downsample_block.has   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>905 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>sample, res_samples = downsample_block(                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">906 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>hidden_states=sample,                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">907 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>temb=emb,                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">908 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>encoder_hidden_states=encoder_hidden_states,                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">94</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unet_2d_bloc</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">993</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 990 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 991 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 992 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>hidden_states = resnet(hidden_states, temb)                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 993 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>hidden_states = attn(                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 994 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 995 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>encoder_hidden_states=encoder_hidden_states,                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 996 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>cross_attention_kwargs=cross_attention_kwargs,                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">94</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">transformer_</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2d.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">291</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">288 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">289 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># 2. Blocks</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">290 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> block <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transformer_blocks:                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>291 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>hidden_states = block(                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">292 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>hidden_states,                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">293 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>attention_mask=attention_mask,                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">294 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>encoder_hidden_states=encoder_hidden_states,                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">94</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">attention.py</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">170</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.norm2(hidden_states, timestep) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.use_ada_layer_norm <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>170 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>attn_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn2(                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>norm_hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>encoder_hidden_states=encoder_hidden_states,                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>attention_mask=encoder_attention_mask,                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">94</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">attention_pr</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ocessor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">321</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 318 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The `Attention` class can call different attention processors / attention func</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 319 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># here we simply pass along all tensors to the selected processor class</span>           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 320 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># For standard processors that are defined here, `**cross_attention_kwargs` is e</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 321 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.processor(                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 322 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 323 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>hidden_states,                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 324 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>encoder_hidden_states=encoder_hidden_states,                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">attention_pr</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ocessor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">467</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 464 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>hidden_states = hidden_states.view(batch_size, channel, height * width).tran  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 465 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 466 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>batch_size, sequence_length, _ = (                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 467 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>hidden_states.shape <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> encoder_hidden_states <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> encoder_hidden_sta  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 469 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>attention_mask = attn.prepare_attention_mask(attention_mask, sequence_length, ba  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 470 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'tuple'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'shape'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m4\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1 \u001b[0mwaveform, sr = load_audio(\u001b[33m'\u001b[0m\u001b[33mgenerated_samples/wm_p1_n1_c7.wav\u001b[0m\u001b[33m'\u001b[0m)                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2 \u001b[0mwaveform = torch.tensor(waveform)                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3 \u001b[0mprompt= \u001b[33m'\u001b[0m\u001b[33mBirds chirping in a dense forest at sunrise\u001b[0m\u001b[33m'\u001b[0m                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m4 noise = inversion_pipeline.invert(waveform, prompt = prompt, num_inference_steps=\u001b[94m100\u001b[0m)        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m5 \u001b[0mreconstructed_waveform = inversion_pipeline.reconstruct_audio(noise)                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m6 \u001b[0m                                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92minvert\u001b[0m:\u001b[94m131\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m         \u001b[0m)                                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Perform the reverse diffusion process\u001b[0m                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m131 \u001b[2m      \u001b[0mnoise_latents = \u001b[96mself\u001b[0m.backward_diffusion(                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m         \u001b[0mlatents,                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m         \u001b[0mencoder_hidden_states=encoder_hidden_states,                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m         \u001b[0mnum_inference_steps=num_inference_steps,                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/autograd/\u001b[0m\u001b[1;33mgrad_mode.py\u001b[0m:\u001b[94m2\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m7\u001b[0m in \u001b[92mdecorate_context\u001b[0m                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 24 \u001b[0m\u001b[2m      \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 25 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 26 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.clone():                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 27 \u001b[2m            \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 28 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m cast(F, decorate_context)                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 29 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 30 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_wrap_generator\u001b[0m(\u001b[96mself\u001b[0m, func):                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92mbackward_diffusion\u001b[0m:\u001b[94m78\u001b[0m                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m         \u001b[0mlatent_model_input = \u001b[96mself\u001b[0m.scheduler.scale_model_input(latent_model_input, t)   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m         \u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m# Predict noise residual\u001b[0m                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 78 \u001b[2m         \u001b[0mnoise_pred = \u001b[96mself\u001b[0m.model.unet(                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2m            \u001b[0mlatent_model_input, t, encoder_hidden_states=encoder_hidden_states         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m         \u001b[0m).sample                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 81 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m11\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m94\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1194 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/\u001b[0m\u001b[1;33munet_2d_cond\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mition.py\u001b[0m:\u001b[94m905\u001b[0m in \u001b[92mforward\u001b[0m                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m902 \u001b[0m\u001b[2m      \u001b[0mdown_block_res_samples = (sample,)                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m903 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m downsample_block \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.down_blocks:                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m904 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(downsample_block, \u001b[33m\"\u001b[0m\u001b[33mhas_cross_attention\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m downsample_block.has   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m905 \u001b[2m            \u001b[0msample, res_samples = downsample_block(                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m906 \u001b[0m\u001b[2m               \u001b[0mhidden_states=sample,                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m907 \u001b[0m\u001b[2m               \u001b[0mtemb=emb,                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m908 \u001b[0m\u001b[2m               \u001b[0mencoder_hidden_states=encoder_hidden_states,                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m11\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m94\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1194 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/\u001b[0m\u001b[1;33munet_2d_bloc\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mks.py\u001b[0m:\u001b[94m993\u001b[0m in \u001b[92mforward\u001b[0m                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 990 \u001b[0m\u001b[2m            \u001b[0m)[\u001b[94m0\u001b[0m]                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 991 \u001b[0m\u001b[2m         \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 992 \u001b[0m\u001b[2m            \u001b[0mhidden_states = resnet(hidden_states, temb)                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 993 \u001b[2m            \u001b[0mhidden_states = attn(                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 994 \u001b[0m\u001b[2m               \u001b[0mhidden_states,                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 995 \u001b[0m\u001b[2m               \u001b[0mencoder_hidden_states=encoder_hidden_states,                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 996 \u001b[0m\u001b[2m               \u001b[0mcross_attention_kwargs=cross_attention_kwargs,                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m11\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m94\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1194 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/\u001b[0m\u001b[1;33mtransformer_\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33m2d.py\u001b[0m:\u001b[94m291\u001b[0m in \u001b[92mforward\u001b[0m                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m288 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# 2. Blocks\u001b[0m                                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m block \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.transformer_blocks:                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m291 \u001b[2m         \u001b[0mhidden_states = block(                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m292 \u001b[0m\u001b[2m            \u001b[0mhidden_states,                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m            \u001b[0mattention_mask=attention_mask,                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m            \u001b[0mencoder_hidden_states=encoder_hidden_states,                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m11\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m94\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1194 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/\u001b[0m\u001b[1;33mattention.py\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m :\u001b[94m170\u001b[0m in \u001b[92mforward\u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m            \u001b[0m\u001b[96mself\u001b[0m.norm2(hidden_states, timestep) \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.use_ada_layer_norm \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m         \u001b[0m)                                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m         \u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m170 \u001b[2m         \u001b[0mattn_output = \u001b[96mself\u001b[0m.attn2(                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m            \u001b[0mnorm_hidden_states,                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m            \u001b[0mencoder_hidden_states=encoder_hidden_states,                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m            \u001b[0mattention_mask=encoder_attention_mask,                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m11\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m94\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1194 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/\u001b[0m\u001b[1;33mattention_pr\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mocessor.py\u001b[0m:\u001b[94m321\u001b[0m in \u001b[92mforward\u001b[0m                                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 318 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# The `Attention` class can call different attention processors / attention func\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 319 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# here we simply pass along all tensors to the selected processor class\u001b[0m           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 320 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# For standard processors that are defined here, `**cross_attention_kwargs` is e\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 321 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.processor(                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 322 \u001b[0m\u001b[2m         \u001b[0m\u001b[96mself\u001b[0m,                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 323 \u001b[0m\u001b[2m         \u001b[0mhidden_states,                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 324 \u001b[0m\u001b[2m         \u001b[0mencoder_hidden_states=encoder_hidden_states,                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/diffusers/models/\u001b[0m\u001b[1;33mattention_pr\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mocessor.py\u001b[0m:\u001b[94m467\u001b[0m in \u001b[92m__call__\u001b[0m                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 464 \u001b[0m\u001b[2m         \u001b[0mhidden_states = hidden_states.view(batch_size, channel, height * width).tran  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 465 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 466 \u001b[0m\u001b[2m      \u001b[0mbatch_size, sequence_length, _ = (                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 467 \u001b[2m         \u001b[0mhidden_states.shape \u001b[94mif\u001b[0m encoder_hidden_states \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m encoder_hidden_sta  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 468 \u001b[0m\u001b[2m      \u001b[0m)                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 469 \u001b[0m\u001b[2m      \u001b[0mattention_mask = attn.prepare_attention_mask(attention_mask, sequence_length, ba  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 470 \u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'tuple'\u001b[0m object has no attribute \u001b[32m'shape'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "waveform, sr = load_audio('generated_samples/wm_p1_n1_c7.wav') \n",
    "waveform = torch.tensor(waveform)\n",
    "prompt= 'Birds chirping in a dense forest at sunrise'\n",
    "noise = inversion_pipeline.invert(waveform, prompt = prompt, num_inference_steps=100)\n",
    "reconstructed_waveform = inversion_pipeline.reconstruct_audio(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f58aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming `noise_tensor` is your output tensor\n",
    "noise_tensor = noise  # Replace with your tensor variable\n",
    "\n",
    "# Squeeze the batch dimension if it's 1 (shape: [batch, channels, height, width])\n",
    "if noise_tensor.shape[0] == 1:\n",
    "    noise_tensor = noise_tensor.squeeze(0)\n",
    "\n",
    "# Select a channel to visualize\n",
    "channel_index = 7  # Change to visualize different channels\n",
    "channel_data = noise_tensor[channel_index].detach().cpu().numpy()  # Convert to NumPy for plotting\n",
    "\n",
    "# Normalize the data for visualization\n",
    "# channel_data = (channel_data - channel_data.min()) / (channel_data.max() - channel_data.min())\n",
    "\n",
    "# Plot the selected channel\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(channel_data, cmap='viridis')  # Change cmap if needed\n",
    "plt.colorbar()\n",
    "plt.title(f\"Channel {channel_index}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming `noise_tensor` is your output tensor\n",
    "noise_tensor = noise  # Replace with your tensor variable\n",
    "\n",
    "# Squeeze the batch dimension if it's 1 (shape: [batch, channels, height, width])\n",
    "if noise_tensor.shape[0] == 1:\n",
    "    noise_tensor = noise_tensor.squeeze(0)\n",
    "\n",
    "# Select a channel to visualize\n",
    "channel_index = 6  # Change to visualize different channels\n",
    "channel_data = noise_tensor[channel_index].detach().cpu().numpy()  # Convert to NumPy for plotting\n",
    "\n",
    "# Normalize the data for visualization\n",
    "# channel_data = (channel_data - channel_data.min()) / (channel_data.max() - channel_data.min())\n",
    "\n",
    "# Plot the selected channel\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(channel_data, cmap='viridis')  # Change cmap if needed\n",
    "plt.colorbar()\n",
    "plt.title(f\"Channel {channel_index}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f12b13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming `noise_tensor` is your output tensor\n",
    "noise_tensor = init_latents  # Replace with your tensor variable\n",
    "\n",
    "# Squeeze the batch dimension if it's 1 (shape: [batch, channels, height, width])\n",
    "if noise_tensor.shape[0] == 1:\n",
    "    noise_tensor = noise_tensor.squeeze(0)\n",
    "\n",
    "# Select a channel to visualize\n",
    "channel_index = 7  # Change to visualize different channels\n",
    "channel_data = noise_tensor[channel_index].detach().cpu().numpy()  # Convert to NumPy for plotting\n",
    "\n",
    "# Normalize the data for visualization\n",
    "# channel_data = (channel_data - channel_data.min()) / (channel_data.max() - channel_data.min())\n",
    "\n",
    "# Plot the selected channel\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(channel_data, cmap='viridis')  # Change cmap if needed\n",
    "plt.colorbar()\n",
    "plt.title(f\"Channel {channel_index}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3abd08f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming `noise_tensor` is your output tensor\n",
    "noise_tensor = noise  # Replace with your tensor variable\n",
    "\n",
    "# Squeeze the batch dimension if it's 1 (shape: [batch, channels, height, width])\n",
    "if noise_tensor.shape[0] == 1:\n",
    "    noise_tensor = noise_tensor.squeeze(0)\n",
    "\n",
    "# Select a channel to visualize\n",
    "channel_index = 7  # Change to visualize different channels\n",
    "channel_data = noise_tensor[channel_index].detach().cpu().numpy()  # Convert to NumPy for plotting\n",
    "\n",
    "# Normalize the data for visualization\n",
    "# channel_data = (channel_data - channel_data.min()) / (channel_data.max() - channel_data.min())\n",
    "\n",
    "# Plot the selected channel\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(channel_data, cmap='viridis')  # Change cmap if needed\n",
    "plt.colorbar()\n",
    "plt.title(f\"Channel {channel_index}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae68fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a001e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
